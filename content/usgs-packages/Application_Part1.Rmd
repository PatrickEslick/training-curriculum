---
title: "Application - Part 1, find sites"
date: "9999-05-25"
author: "Lindsay R. Carr"
slug: "app-part1"
image: "img/main/intro-icons-300px/r-logo.png"
output: USGSmarkdowntemplates::hugoTraining
parent: Introduction to USGS R Packages
weight: 41
draft: true
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
library(knitr)

knit_hooks$set(plot=function(x, options) {
  sprintf("<img src='../%s%s-%d.%s'/ title='%s'/>", 
          options$fig.path, options$label, options$fig.cur, options$fig.ext, options$fig.cap)

})

opts_chunk$set(
  echo=TRUE,
  fig.path="static/application/",
  fig.width = 6,
  fig.height = 6,
  fig.cap = "TODO"
)

knit_hooks$set(addToggle = function(before, options, envir) {
    if(before) {
      sprintf('<button class="ToggleButton" onclick="toggle_visibility(\'%1$s\')">Show Answer</button>
              <div id="%1$s" style="display:none">', opts_current$get('label'))
    } else {
      '</div>'
    }
})

set.seed(1)
```

```{r sbtools-auth, echo=FALSE}
# run vizlab::storeSBcreds() once before this can work
credList <- readRDS(file.path(path.expand('~'), ".vizlab/sbCreds"))
un <- rawToChar(credList$username)
pw <- rawToChar(credList$password)
sbtools::authenticate_sb(un, pw)
```

As stated in the Challenge description, site information has been provided via ScienceBase. For the purposes of this exercise, let's assume your cooperator gave you the [link to the ScienceBase item](https://www.sciencebase.gov/catalog/item/59848b35e4b0e2f5d46717d1) that contained the site information. Using functions taught earlier in `sbtools` lessons, create a vector of the ScienceBase site numbers. In addition, use functions in `dataRetrieval` to gather relevant location data about each site (e.g. HUC ids).

## Get sites

First, authenticate your ScienceBase session using `authenticate_sb()`. Now, use `sbtools` functions to read the appropriate file from the [SB item created by your cooperator](https://www.sciencebase.gov/catalog/item/59848b35e4b0e2f5d46717d1) into R as a data frame. Try it on your own before looking at the answer below. Don't hesitate to go back to the [sbtools download data lesson](/usgs-packages/sbtools-get) for a refresher.

```{r get-sb-sites, addToggle="ON", message=FALSE, warning=FALSE}
library(sbtools)

# identify site id and query for files
sb_site_id <- "59848b35e4b0e2f5d46717d1"
avail_files <- item_list_files(sb_site_id)

# look at what files are available and choose which you want
avail_files

# use appropriate reader to get file into R
sb_sites_df <- read.table(avail_files$url[1], sep="\t", header=TRUE,
                          colClasses = "character", stringsAsFactors = FALSE)
head(sb_sites_df)
```

Create a vector of just site numbers to use for subsequent functions.

```{r create-site-vec, addToggle="ON"}
sites <- sb_sites_df$site_number
sites
```

## Get relevant site metadata

In anticipation of downloading precipitation data through the Geo Data Portal, we need to determine which regions to use since it does not operate based on NWIS sites. GDP can use 8-digit hydrologic unit codes (HUCs), which can be determined for each site number using `readNWISsite`. Use `readNWISsite` to get a vector of 8-digit HUCs. Try it on your own before looking at the answer below.

```{r get_hucs, addToggle="ON", message=FALSE, warning=FALSE}
library(dataRetrieval)
sb_sites_info <- readNWISsite(sites)

# look at column names to find where the HUC codes live
names(sb_sites_info)

huc8s <- sb_sites_info$huc_cd
huc8s
```
